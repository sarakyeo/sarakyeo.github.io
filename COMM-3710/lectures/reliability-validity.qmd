---
title: "Reliability and Validity"
format:
    revealjs:
        show-notes: false
---

## Week 7

- Extra credit opportunity: Take the survey (link in Announcement on Canvas)
- Reliability
    - Statistical ways to examine reliability
    - Improving reliability
- Validity
    - Types/Approaches to validity
- Measurement problems related to reliability and validity

---

## Criteria of Measurement Quality

How do we judge success / failure for measuring concepts?

:::{.incremental}
:::{.columns}
:::{.column width="40%"}

- reliability
- validity

:::
:::{.column width="60%"}

- consistency of measurement
- confidence in measures

:::
:::
:::

---

## Reliability

- refers to <mark>**whether a measure produces stable, consistent measurement**</mark>
- analogous to precision
- if you measure multiple times, values should not change

Scalar reliability

- reliability of research scales
- most commonly assessed

---

## Scalar Reliability: An Example

![](reliability-validity-01.png){fig-align="center"}

:::{.notes}

We have to examine how people are answering our measure of attitudes toward higher education. We will talk about how individual respondents can answer scales such as this, but when assessing reliability of a measure, we need to look collectively at the respondents’ scores to a scale, not just individual scores. Some people will respond inconsistently, but, hopefully, most will respond consistently. We need some way to evaluate whether these responses are consistent across the sample—we need statistical ways of doing this.

:::

---

## 

![](reliability-validity-02.png){fig-align="center"}

:::{.notes}

This is what responses should look like if participants have positive (top) or negative (botton) feelings about higher education.

:::

---

##

On the scale below, please indicate your feelings about **"Higher Education."**

![](reliability-validity-03.png){fig-align="center"}

:::{.notes}

But sometimes we get responses that look like this. What's the problem here? ... However, we don't know whether these responses are "real" or whether they are due to lack of attention, misunderstanding of the questions, etc. We have to have statistical ways to collectively look at how reliably respondents' have answered this question using this scale to find out.

:::

---

## Statistical Ways to Examine Reliability

1) Test-retest reliability
2) Alternate forms reliability
3) Average inter-item reliability
4) Split-half reliability
5) Cronbach’s alpha ($\alpha$)

---

## Test-Retest Reliability

Assessing consistency over time

- use the test-retest method with the same respondents
- compare responses to the <mark>same measure</mark> at $t_1$ and $t_2$
- good reliability coefficient is between ~0.7 and 0.9

![](reliability-validity-04.jpg){fig-align="center"}

:::{.notes}

Test–retest reliability for attitude measures is estimated by administering the instrument to the same group of people on two occasions, separated by some given amount of time. Good attitude-measuring instruments normally produce test–retest reliability coefficients of 0.70 or above, and many coefficients are 0.90 or above. If a researcher finds a test–retest reliability below 0.70, then her or his participants are not responding to the scale consistently. Conversely, test–retest reliability coefficients of about 0.90 indicate that people are filling out the scale at Time 1 and Time 2 in almost identical fashion.

:::

---

## Alternate Forms Reliability

Also assessing consistency over time

- use the test-retest method with the same respondents
- compare responses to the <mark>different measure</mark> at $t_1$ and $t_2$
- good reliability coefficient will be slightly lower than test-retest method

![](reliability-validity-05.jpg){fig-align="center"}

--- 

## Assessing inter-item reliability

:::{.columns}
:::{.column width="50%"}
![](reliability-validity-06.jpg){fig-align="center"}
:::

:::{.column width="50%" }
- Average inter-item reliability
- Split-half reliability
- Cronbach's alpha ($\alpha$)
:::
:::

