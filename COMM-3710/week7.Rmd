---
title: |
  | COMM 3710: Reliability and Validity
pagetitle: "COMM 3710: Week 7"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
urlcolor: blue
---

# What is Reliability and Validity?
> **Reliability** and **validity** are standards by which we judge success or failure in our measurement of concepts.

**Reliability**

- Reliability is a quality of measurement that refers to <mark>consistency</mark> of a measure. When we assess reliability of a measure, we are asking whether the measure is a consistent indicator of a concept

**Validity**

- Validity is a quality of measurement that refers to <mark>accuracy</mark> of a measure. A measure that is valid accurately reflects the concept it is intended to measure. The concept of validity also extends to...

   1. precision in study design (**internal validity**, which is important in experiments)
   2. our ability to generalize findings from a sample to a larger population (**external validity**)

Reliability and validity can be thought of as precision and accuracy, respectively. Using these four terms (*reliability*, *validity*, *precision*, and *accuracy*), describe the dart-thrower in scenarios A, B, and C below.

```{r, rel-val-01, echo=FALSE, message=FALSE, warning=FALSE, out.width = "100%", fig.align='center'}

knitr::include_graphics("https://sarakyeo.github.io/images/rel-val-01.png")

```

Answers can be found in the video below.

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/RgDfNMND0GA" frameborder="0" data-external="1" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>
<br>


# Types of Reliability {.tabset .tabset-fade}
There are four (4) types of reliability:

1. Stability
2. Reproducibility
3. Homogeneity
4. Accuracy

Click on the tabs below to learn more about each type of reliability.

## Stability
Refers to consistency in measures across time. We can evaluate stability using a test-retest method. By measuring a concept at time 1 ($t_1$) and time 2 ($t_2$), we can compare them to see if they are stable across time.

```{r, stability, echo=FALSE, message=FALSE, warning=FALSE, out.width = "100%", fig.align='center'}

knitr::include_graphics("https://sarakyeo.github.io/images/stability.png")

```

## Reproducibility
Refers to consistency between observers. By comparing the results of two different observers who are measuring the same phenomenon using the same measuring device, we can determine whether we have reliability between observers. This reliability between observers is known as **inter-coder reliability**.

```{r, reprod, echo=FALSE, message=FALSE, warning=FALSE, out.width = "100%", fig.align='center'}

knitr::include_graphics("https://sarakyeo.github.io/images/reproducibility.png")

```

## Homogeneity
Refers to consistency between different measures of a single concept. We often use more than one indicator to measure a concept. Homogeneity refers to the reliability of the indicators of a concept. We assess this using **inter-item reliability**. The next section discusses assessing inter-item reliability in more detail.

## Accuracy
Refers to the lack of mistakes in measurement. We can increase accuracy of measures by having clear, defined procedures. In addition, observers must have sufficient training, motivation, and concentration.


# Assessing Inter-Item Reliability
Inter-item reliability refers to the correlation of each item/indicator with every other item/indicator used in measurement of a particular concept. To begin, let's first clarify the meaning of a **statistical correlation**.

A **statistical correlation** is a measure of the strength and direction of the relationship between two variables. The three figures below show three different types of relationships (negative, neutral, or positive). See if you can identify the type of relationship in the figure.

```{r, r-neu, echo=FALSE, message=FALSE, warning=FALSE, out.width = "30%", fig.align='center'}

knitr::include_graphics("https://sarakyeo.github.io/images/r-neu.png")

```

```{r, r-pos, echo=FALSE, message=FALSE, warning=FALSE, out.width = "30%", fig.align='center'}

knitr::include_graphics("https://sarakyeo.github.io/images/r-pos.png")

```

```{r, r-neg, echo=FALSE, message=FALSE, warning=FALSE, out.width = "30%", fig.align='center'}

knitr::include_graphics("https://sarakyeo.github.io/images/r-neg.png")

```

Check your answers with the [Week 4 lecture on relationships](https://sarakyeo.github.io/COMM-3710/week4.html#Relationships).

We often examine linear associations/relationships between two variables (such as the linear relationships between $X$ and $Y$ depicted in the graphs above) using **Pearson correlation coefficients ($r$)**. Pearson's correlation is commonly used to measure the strength of a linear association between two variables. These coefficients are often displayed in tables, which show the inter-item correlation between variables in the rows and columns.

$r$ ranges between $-1$ and $1$ and cannot exceed these boundaries. In other words, $r$ can only have a value between $-1$ and $1$. The sign of $r$ tells us whether the relationship is positive or negative, and the value tells us about the strength of the linear relationship between the two variables.

Values of $r$ closer to $+1$ indicate a stronger positive relationship and values of $r$ closer to $-1$ indicate a stronger negative relationship. $r = 0$ means there is no linear relationship between the variables.

Let's take a look at the example below, which shows correlation coefficients for *attention to news* on various media platforms.

```{r, corr-coefs, echo=FALSE, message=FALSE, warning=FALSE, out.width = "80%", fig.align='center'}

knitr::include_graphics("https://sarakyeo.github.io/images/corr-coefs.png")

```

From this table, we can see that the relationship between *attention to news on TV* and *attention to news on the radio* is $0.89$. To check your understanding of how to read tables like these, see whether you are able to determine the Pearson correlation coefficient for the relationship between *attention to news in blogs* and *attention to news on the radio*.^[The answer is $0.75$.]

<hr>

To assess inter-item reliability, we use one of three ways. The video below explains each of these.

1. Average inter-item correlation
2. Split-half reliability
3. Cronbach's alpha ($\alpha$)

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/1HObEfdRT3s" frameborder="0" data-external="1" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>
<br>


# Approaches to Validity
There are three primary approaches or types of validity that we will cover in this course. One can be assessed before data collection, while the remaining two are assessed after data collection.

Before data collection, we can assess:

1. face or content validity

After data collection, we can assess:

2. criterion validity
3. construct validity

> Read **Chapter 8** of your textbook and make note of the definitions of these terms.


# Summary
Here's a graphical summary of what we have covered on reliability and validity of measures. Remember to ask any questions about this week's content in lab.

```{r, rel-val-summary, echo=FALSE, message=FALSE, warning=FALSE, out.width = "100%", fig.align='center'}

knitr::include_graphics("https://sarakyeo.github.io/images/rel-val-summary.png")

```
