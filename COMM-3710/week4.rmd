---
title: |
  | <a name="top"></a>
  | COMM 3710: Variables and Measurement
pagetitle: "COMM 3710: Week 4"
output:
  html_document:
    toc: true
    toc_float: true
    theme: united
urlcolor: blue
---
<a name="var"></a>

# What is a Variable? {.tabset .tabset-fade}
A **variable** can be defined as any entity that can take on a variety of different values. Research deals with the measurement, manipulation, and control of variables to test hypotheses and answer research questions.

A **variable** is a concept or construct that varies. Some variables are **concrete variables** and some are **abstract variables**.

**Concrete variables** are those that are stable or consistent over time. Some examples of this are eye color (e.g., blue, green, brown) and biological sex (male/female).

**Abstract variables** are those that change over time or across situations or contexts. Some examples are attitudes and opinions.

Before discussing relationships and differences between variables, we need to cover aspects of variables and some types of variables that we will encounter in this course.

## Aspects of Variables
Each variable has its associated aspects. These aspects include **variable attributes** and **variable values**.

**Variable attributes** are specific categories of a variable. Consider the variable, *eye color*. The attributes of this variable might be *brown*, *blue*, *green*.

**Variable values** are the numeric designation assigned to each variable attribute. This allows variables to be analyzed using statistics. For example, if our attributes of *eye color* are *brown*, *blue*, and *green*, we could use numbers to designate a color, i.e., 1 = *brown*, 2 = *blue*, 3 = *green*.

<u>Another example:</u>

- Variable: Journalists' confidence in their own reporting abilities
- Variable attributes:
   - `Not at all confident`,
   - `Slightly confident`,
   - `Somewhat confident`,
   - `Moderately confident`,
   - `Very confident`
- Variable values:
   - 1 = `Not at all confident`,
   - 2 = `Slightly confident`,
   - 3 = `Somewhat confident`,
   - 4 = `Moderately confident`,
   - 5 = `Very confident`

<center>
<img src="https://sarakyeo.github.io/images/aspects-variables.png"/>
</center>
<br>

<a href="#top">Back to top</a>

## Types of Variables
A **dependent variable** (DV) is one that is not manipulated or changed by the researcher. Instead, researchers are looking for change in the dependent variable as a result of the change in some other, independent variable. One way to remember this: The dependent variable depends on the independent variable. The dependent variable is also sometimes called the **outcome** or **criterion variable**.

An **independent variable** (IV) is one that affects the outcome/dependent variable. In experiments, the independent variable is one that researchers manipulate or change. The independent variable is also often called the **predictor variable**.

<center>
<img src="https://sarakyeo.github.io/images/iv-dv.png"/>
</center>
<br>

Use the Week 4 Discussion page on Canvas to discuss the answers with your peers.

<a href="#top">Back to top</a>


# Understanding Relationships and Differences
All variables in research enable us to understand two basic phenomena: **relationships** and **differences**. Click on the tabs below to learn about these phenomena.

## Relationships {.tabset .tabset-fade}
In research, **relationships** refer to connections between variables. Most communication studies are designed with the goal of identifying relationships between variables.

For example, Yeo et al. (2014) studied the relationship between people's *perceptions of risk related to nuclear energy* and *attention to media*.

<center>
<img src="https://sarakyeo.github.io/images/Yeo-et-al-2014.png"/>
</center>
<br>

Relationships typically fall into one of three categories: **positive**, **negative**, or **neutral**. We typically use a number, known as Pearson's correlation coefficient (denoted by *r*) to describe the strength and direction of a relationship. This is an inferential statistic that we can compute (and we will do so in our group projects).

**Pearson's correlation coefficient** ranges between **-1 and 1**.

- The sign of *r* tells us whether the relationship is positive or negative.
- The magnitude of *r* tells us about the strength of the relationship.
- A *r*-value of 0.8 is considered a strong, positive relationship, while a *r*-value of -0.8 is considered to be a strong, negative relationship.

### Positive
Positive relationships exist when an increase in one variable results in an increase in another variable. Note that, in a positive relationship, when one variable decreases, the other also decreases. In other words, the variables move in the same direction.

Let's say $X$ is an independent variable and $Y$ is a dependent variable.

In a positive relationship, when $X$ $\Uparrow$, $Y$ $\Uparrow$. Also, when $X$ $\Downarrow$, $Y$ $\Downarrow$. Graphically, the relationship between $X$ (independent variable) and $Y$ (dependent variable) would look like:

<center>
<img src="https://sarakyeo.github.io/images/pos-rel.png"/>
</center>
<br>

<a href="#top">Back to top</a>

### Negative
Negative relationships exist when an increase in one variable results in a decrease in another variable.

Again, say $X$ is an independent variable and $Y$ is a dependent variable.

In a negative relationship, when $X$ $\Uparrow$, $Y$ $\Downarrow$. Also, when $X$ $\Downarrow$, $Y$ $\Uparrow$. Graphically, the relationship between $X$ (independent variable) and $Y$ (dependent variable) would look like:

<center>
<img src="https://sarakyeo.github.io/images/neg-rel.png"/>
</center>
<br>

<a href="#top">Back to top</a>

### Neutral
A **neutral relationship** is on in which the variables are not related. In other words, it is the lack of a relationship and changes in one variable do not result in changes in the other.

Again, if $X$ is an independent variable and $Y$ is a dependent variable, a neutral relationship would look like this:

<center>
<img src="https://sarakyeo.github.io/images/neu-rel.png"/>
</center>
<br>

<a href="#top">Back to top</a>


## Differences {.tabset .tabset-fade}
Statistics also enables researchers to examine differences. In research, differences can fall into one of two categories: **differences in kind** and **difference in degree**. As researchers, we are more interested in *differences in degree*.

### Differences in Kind
**Differences in kind** occur when different groups do different things. For example, teachers teach students and musicians play music. We wouldn't expect a musician to replace a teacher or a teacher to replace a musician. In research and statistics, differences in kind are not very interesting, except when they are used as grouping variables (e.g., one group of survey participants is female and another is male).

<a href="#top">Back to top</a>

<hr>

### Differences of Degree
Researchers are often interested in **differences of degree**. This is when two groups have different degrees of a variable. For example, women tend to be more averse to risk than men. In other words, in general, women tend to perceive more risk than men.

Using statistical tests of difference allows researchers to determine whether there is a statistically significant difference in risk perceptions between women and men.

For a visual depiction of differences of degree, see Figures 6.4 and 6.5 in your textbook.

<a href="#top">Back to top</a>

---

# Measurement
**Measurement** is the process of systematic observation in which we assign numbers to the things we measure. Measurement is a way for us to observe the "seen" (e.g., eye color, biological sex) and the "unseen" (e.g., attitudes, perceptions). To clarify your understanding about measurement as a *process*, read the section titled **"Defining the Term" in Chapter 6 of your textbook**.

<br>

But why do we assign numbers to things we measure?

In general, we want to be able to quantify information so that...
1. we can increase our objectivity,
2. we can conduct statistical tests,
3. we can standardize (i.e., have rules about) how we assess obvious (e.g., demographic) and latent (e.g., attitudes) characteristics.

## Levels of Measurement {.tabset .tabset-fade}
Levels of measurement allow us to have precision when we measure variables. The **level of measurement** refers to the relationship among values assigned to the attributes of a variable. Refer to <a href="#var">What is a Variable?</a> to review the definitions of *variable attribute* and *variable value*.

<center>
<img src="https://sarakyeo.github.io/images/level-of-meas.png"/>
</center>
<br>

Quantitative data can be measured as **categorical/discrete** or **continuous** variables. Each of these broad categories has two levels of measurement.

<center>
<img src="https://sarakyeo.github.io/images/meas01.png"/>
</center>
<br>

Click on the tabs below to learn about the four levels of measurement. The figure below summarizes the four levels based on how precise (or how much information contained in each level) they are.

<center>
<img src="https://sarakyeo.github.io/images/meas02.png"/>
</center>
<br>


### Nominal
*Nominal* measures or variables categorize data into **mutually exclusive** categories. There is no logical order to the variable attributes even though we assign values to them. In other words, the variable values have no logical rank-order. Examples include political partisanship (Democrat, Republican, Independent, other, etc.) and eye color (e.g., blue, brown, green, other).

<u>Example</u>: Political partisanship

Variable values and attributes:

- 1 = `Democrat`
- 2 = `Republican`
- 3 = `Other`

Even though we assign values to the attributes, there is no logical order to them, i.e., Democrats are not lower in rank than Republicans who are, in turn, not lower in rank than those who selected "Other."

<br>

There is a special type of nominal measure called a **binary** measure. One example of this is biological sex (male or female). A binary measure only has two categories. As with all nominal variables, sex cannot be rank-ordered--it makes no sense for males to be ranked higher/lower than females. They are simply different in kind, or different categories/groupings.

Nominal data are typically reported as proportions or percentages.

<center>
<img src="https://sarakyeo.github.io/images/nominal.png"/>
</center>
<br>

<a href="#top">Back to top</a>

### Ordinal
**Ordinal variables** have a logical order to the categories used to represent variable attributes. Again, the categories must be mutually exclusive--a respondent should only "fit" into one category.

Examples of ordinal variables include household income, level of education, military rank, etc.

<u>Example</u>: Household income

Variable values and attributes

- 1 = `Under $30,000`
- 2 = `$30,000 to $49,999`
- 3 = `$50,000 to $74,999`
- 4 = `$75,000 to $99,999`
- 5 = `$100,000 or more`

Note that the variable attributes (and values) have a logical rank order but the distance or space between each category is not always the same. This is another important characteristic of ordinal variables: The intervals between each category are not necessarily representative of equal distances or quantities.

Lastly, there is no zero point in an ordinal variable. In other words, there is no absence of household income, level of education, or military rank (at least not they way we are measuring these variables). 

<br>

Here's another example of an ordinal variable:
<center>
<img src="https://sarakyeo.github.io/images/ordinal.png"/>
</center>
<br>

<a href="#top">Back to top</a>

### Interval
**Interval variables** categorize variable attributes in a logical order that represents equal distances between each category. Attitudes, risk perceptions, opinions, and behavioral intentions are examples of interval measures, if we assume the distance between each variable attribute to be equal or constant.

<u>Example</u>: Risk perceptions

Variable attributes

- 1 = `Not at all risky`
- 2 = `Slightly risky`
- 3 = `Moderately risky`
- 4 = `Very risky`

Note that we are assuming the distances between attributes to be equal in this example. If we did not make this assumption, this measure of *risk perception* would be an ordinal variable. There is also no absolute zero point. In other words, there is no *absence* of perception in this scale.

<br>

Another example is temperature:
<center>
<img src="https://sarakyeo.github.io/images/ordinal.png"/>
</center>

Again, $0^\circ C$ is an arbitrarily defined zero-point (freezing).

<a href="#top">Back to top</a>

### Ratio
**Ratio variables** share all the characteristics of interval variables except that ratio variables have an absolute zero point. In other words, there can be an absence of the variable that is being measured. For example, test scores, number of days one reads a newspaper, and speed are ratio variables.

All these examples have mutually exclusive categories, the distances between variable attributes are equal, and they all have a "real" (or absolute) zero, i.e., absence of a characteristic. 

<a href="#top">Back to top</a>